{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import getSubset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(linear, self).__init__()\n",
    "        self.li1 = nn.Linear(5, 36)\n",
    "        self.li2 = nn.Linear(36, 64)\n",
    "        self.li3 = nn.Linear(64, 5)\n",
    "        self.bn1 = nn.BatchNorm1d(36)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.li1(x)\n",
    "        self.bn1(x)\n",
    "        x = self.li2(x)\n",
    "        self.bn2(x)\n",
    "        return self.li3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  tensor([[0.9049, 0.0338, 0.6938, 0.9239, 0.8570],\n",
      "        [0.3320, 0.6364, 0.0343, 0.6900, 0.2239]], device='cuda:0')\n",
      "output:  tensor([[-0.0715, -0.0005, -0.1904, -0.0049, -0.0508],\n",
      "        [ 0.0174,  0.0156,  0.0123,  0.0386, -0.0521]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = linear().cuda()\n",
    "x = torch.rand(2, 5).cuda()\n",
    "print('input: ', x)\n",
    "res = net(x)\n",
    "print('output: ', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename: str):\n",
    "    '''\n",
    "    导入指定的文件\n",
    "    file: e.g. G:\\深度学习\\医疗\\icentia-ecg\\icentia-ecg\\datasets\\\n",
    "    返回一个ndarray类型的数组，是文件的读取结果，尺寸为(50, 1048578)，最后一列记录当前一横行数据的采集者，范围0~10999\n",
    "    '''\n",
    "    # print(\"load file:\", filename)\n",
    "    data = pickle.load(gzip.open(filename))\n",
    "    # print(type(data), data)\n",
    "    idx = int(filename.split('/')[-1][:5])\n",
    "    temp = idx * np.ones((data.shape[0], 1)) # (50, 1)\n",
    "    data = np.concatenate([data, temp], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取datasets/00001_batched.pkl.gz (50, 1048578)\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Compressed file ended before the end-of-stream marker was reached",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m res1 \u001b[38;5;241m=\u001b[39m load_file(file1)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m读取\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, res1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 5\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m读取\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, res\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn [13], line 8\u001b[0m, in \u001b[0;36mload_file\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m导入指定的文件\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mfile: e.g. G:\\深度学习\\医疗\\icentia-ecg\\icentia-ecg\\datasets\\\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m返回一个ndarray类型的数组，是文件的读取结果，尺寸为(50, 1048578)，最后一列记录当前一横行数据的采集者，范围0~10999\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# print(\"load file:\", filename)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# print(type(data), data)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(filename\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m5\u001b[39m])\n",
      "File \u001b[1;32md:\\DesktopEXE\\Anaconda\\envs\\torchgpu\\lib\\gzip.py:292\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39merrno\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(errno\u001b[39m.\u001b[39mEBADF, \u001b[39m\"\u001b[39m\u001b[39mread() on write-only GzipFile object\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 292\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mread(size)\n",
      "File \u001b[1;32md:\\DesktopEXE\\Anaconda\\envs\\torchgpu\\lib\\_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadinto\u001b[39m(\u001b[39mself\u001b[39m, b):\n\u001b[0;32m     67\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b) \u001b[39mas\u001b[39;00m view, view\u001b[39m.\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m byte_view:\n\u001b[1;32m---> 68\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m(byte_view))\n\u001b[0;32m     69\u001b[0m         byte_view[:\u001b[39mlen\u001b[39m(data)] \u001b[39m=\u001b[39m data\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(data)\n",
      "File \u001b[1;32md:\\DesktopEXE\\Anaconda\\envs\\torchgpu\\lib\\gzip.py:498\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m buf \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 498\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCompressed file ended before the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mend-of-stream marker was reached\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    501\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_read_data( uncompress )\n\u001b[0;32m    502\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pos \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(uncompress)\n",
      "\u001b[1;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
     ]
    }
   ],
   "source": [
    "file1 = 'datasets/00001_batched.pkl.gz'\n",
    "file2 = 'datasets/03873_batched.pkl.gz'\n",
    "res1 = load_file(file1)\n",
    "print(f'读取{file1}', res1.shape)\n",
    "res = load_file(file2)\n",
    "print(f'读取{file2}', res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  torch.Size([16, 100, 512])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3357081600 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;124m'\u001b[39m, a\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 3\u001b[0m trans \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConvTranspose1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2049\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m res \u001b[38;5;241m=\u001b[39m trans(a)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout: \u001b[39m\u001b[38;5;124m'\u001b[39m, res\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32md:\\DesktopEXE\\Anaconda\\envs\\torchgpu\\lib\\site-packages\\torch\\nn\\modules\\conv.py:780\u001b[0m, in \u001b[0;36mConvTranspose1d.__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, groups, bias, dilation, padding_mode, device, dtype)\u001b[0m\n\u001b[0;32m    778\u001b[0m dilation \u001b[39m=\u001b[39m _single(dilation)\n\u001b[0;32m    779\u001b[0m output_padding \u001b[39m=\u001b[39m _single(output_padding)\n\u001b[1;32m--> 780\u001b[0m \u001b[39msuper\u001b[39;49m(ConvTranspose1d, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    781\u001b[0m     in_channels, out_channels, kernel_size, stride, padding, dilation,\n\u001b[0;32m    782\u001b[0m     \u001b[39mTrue\u001b[39;49;00m, output_padding, groups, bias, padding_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs)\n",
      "File \u001b[1;32md:\\DesktopEXE\\Anaconda\\envs\\torchgpu\\lib\\site-packages\\torch\\nn\\modules\\conv.py:619\u001b[0m, in \u001b[0;36m_ConvTransposeNd.__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mOnly \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m padding mode is supported for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n\u001b[0;32m    618\u001b[0m factory_kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m: device, \u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m: dtype}\n\u001b[1;32m--> 619\u001b[0m \u001b[39msuper\u001b[39;49m(_ConvTransposeNd, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    620\u001b[0m     in_channels, out_channels, kernel_size, stride,\n\u001b[0;32m    621\u001b[0m     padding, dilation, transposed, output_padding,\n\u001b[0;32m    622\u001b[0m     groups, bias, padding_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs)\n",
      "File \u001b[1;32md:\\DesktopEXE\\Anaconda\\envs\\torchgpu\\lib\\site-packages\\torch\\nn\\modules\\conv.py:128\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice \u001b[39m=\u001b[39m _reverse_repeat_tuple(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39m2\u001b[39m)\n\u001b[0;32m    127\u001b[0m \u001b[39mif\u001b[39;00m transposed:\n\u001b[1;32m--> 128\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39;49mempty(\n\u001b[0;32m    129\u001b[0m         (in_channels, out_channels \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m groups, \u001b[39m*\u001b[39;49mkernel_size), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs))\n\u001b[0;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(\n\u001b[0;32m    132\u001b[0m         (out_channels, in_channels \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m groups, \u001b[39m*\u001b[39mkernel_size), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3357081600 bytes."
     ]
    }
   ],
   "source": [
    "a = torch.rand(16, 100, 512)\n",
    "print('input: ', a.shape)\n",
    "trans = nn.ConvTranspose1d(in_channels=2049, out_channels=2048*2, kernel_size=100, stride=1, dilation=1, groups=1, bias=True)\n",
    "res = trans(a)\n",
    "print('out: ', res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2048, 2049, 100, 1]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 100, 2049,  2048]\n",
    "print(a[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m gemp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      4\u001b[0m temp \u001b[38;5;241m=\u001b[39m temp\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgemp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(temp\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(temp[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten())\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_cat)"
     ]
    }
   ],
   "source": [
    "temp = torch.rand(2,1,3)\n",
    "gemp = torch.rand(1,1,3)\n",
    "\n",
    "temp = temp.cuda()\n",
    "torch.cat([temp, gemp], dim=0)\n",
    "\n",
    "print(temp.flatten(1).shape)\n",
    "print(temp[:, :, -1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3]\n",
      " [4 5 6 7]] [[12 13 14 15]\n",
      " [16 17 18 19]] [[24 25 26 27]\n",
      " [28 29 30 31]]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([i for i in range(8)]).reshape(2,4)\n",
    "b=np.array([i for i in range(12,20)]).reshape(2,4)\n",
    "c=np.array([i for i in range(24,32)]).reshape(2,4)\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 4) [[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]]\n",
      "\n",
      " [[12 13 14 15]\n",
      "  [16 17 18 19]]\n",
      "\n",
      " [[24 25 26 27]\n",
      "  [28 29 30 31]]]\n"
     ]
    }
   ],
   "source": [
    "new_array=np.stack([a,b,c],axis=0)\n",
    "print(new_array.shape, new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename: str):\n",
    "    '''导入指定的文件'''\n",
    "    # print(\">\", filename)\n",
    "    data = pickle.load(gzip.open(filename))\n",
    "    print(data.shape)\n",
    "    idx = int(filename.split('/')[-1][:5])\n",
    "    temp = idx * np.ones((data.shape[0], 1)) # (50, 1)\n",
    "    data = np.concatenate([data, temp], axis=1)\n",
    "    print(data.shape)\n",
    "    print(data[-5:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1048577)\n",
      "(50, 1048578)\n",
      "[[-0.01344722 -0.01344722 -0.01344722 ...  0.01344722  0.01344722\n",
      "   1.        ]\n",
      " [ 0.02689444  0.02689444  0.04034166 ... -0.01344722 -0.01344722\n",
      "   1.        ]\n",
      " [ 0.08068331  0.06723609  0.05378887 ...  0.04034166 -0.01344722\n",
      "   1.        ]\n",
      " [-0.06723609 -0.04034166  0.02689444 ... -0.01344722 -0.01344722\n",
      "   1.        ]\n",
      " [-0.01344722 -0.01344722 -0.01344722 ... -0.17481384 -0.06723609\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "file = load_file('datasets/00001_batched.pkl.gz')\n",
    "# print(type(file))\n",
    "# print(file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97758267 0.38901492 0.80206748 0.64696906 0.17957878 0.24085781\n",
      " 0.79099158 0.21342157 0.47006748 0.98336314]\n",
      "(1, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(10)\n",
    "print(x)\n",
    "emb = x[None, None, :]\n",
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache G:\\深度学习\\医疗\\icentia-ecg\\icentia-ecg/.cache/1200_a3834861caaee2b35b754567601dc021_18536351bee99d761ac3a06f4b42d98c.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "data, labels = getSubset(1200,\n",
    "     embeddings_file='test_emb.csv.gz',\n",
    "                                   labels_file='test_labels.csv.gz',\n",
    "                                   seed=1,\n",
    "                                   balanced='btype')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       0         1         2  ...      2046      2047    2048\\r\n",
      "id                                            ...                              \n",
      "9000_0_90259   -0.094131 -0.094131 -0.094131  ... -0.013447 -0.040342 -0.053789\n",
      "9000_0_774872   0.026894  0.013447  0.013447  ...  0.094131  0.067236  0.053789\n",
      "9000_1_282137   0.000000  0.000000  0.013447  ... -0.026894 -0.040342 -0.026894\n",
      "9000_1_617011  -0.053789 -0.053789 -0.053789  ...  0.026894  0.026894  0.026894\n",
      "9000_1_830028   0.174814  0.174814  0.174814  ...  0.000000  0.000000  0.000000\n",
      "...                  ...       ...       ...  ...       ...       ...       ...\n",
      "9001_35_366486 -0.026894 -0.040342 -0.053789  ... -0.040342 -0.040342 -0.026894\n",
      "9001_36_514000  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
      "9001_37_64110   0.026894  0.053789  0.067236  ...  0.040342  0.040342  0.040342\n",
      "9001_37_831753 -0.174814 -0.174814 -0.188261  ...  0.000000  0.000000  0.000000\n",
      "9001_38_86383   0.040342  0.161367  0.363075  ... -0.013447  0.000000  0.000000\n",
      "\n",
      "[180 rows x 2049 columns]\n",
      "                sample  segment   frame  btype  rtype\n",
      "id                                                   \n",
      "9000_0_90259      9000        0   90259      2      0\n",
      "9000_0_774872     9000        0  774872      1      0\n",
      "9000_1_282137     9000        1  282137      2      0\n",
      "9000_1_617011     9000        1  617011      1      0\n",
      "9000_1_830028     9000        1  830028      1      0\n",
      "...                ...      ...     ...    ...    ...\n",
      "9001_35_366486    9001       35  366486      0      0\n",
      "9001_36_514000    9001       36  514000      0      0\n",
      "9001_37_64110     9001       37   64110      0      0\n",
      "9001_37_831753    9001       37  831753      0      0\n",
      "9001_38_86383     9001       38   86383      0      0\n",
      "\n",
      "[180 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'model': 'knn',\n",
    "    'num_examples': 1200,\n",
    "    'label_type': 'bytes',\n",
    "    'encode_method': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\"model\": args['model'],\n",
    "           \"num_examples\": int(args['num_examples']),\n",
    "           \"label_type\": args['label_type'],\n",
    "           \"seed\": int(233),\n",
    "           \"encode_method\": args['encode_method']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>label_type</th>\n",
       "      <th>seed</th>\n",
       "      <th>encode_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>1200</td>\n",
       "      <td>bytes</td>\n",
       "      <td>233</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  num_examples label_type  seed encode_method\n",
       "0   knn          1200      bytes   233          None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('torchgpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "808ba20632a941d426494906f9e1a2bcb2af5a0b26e589ffbedba9846380e600"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
